{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FASTA import fasta\n",
    "from VARIANT import mutation\n",
    "from DRUG_ID import drug_id\n",
    "from DRUG_SMILES import drug_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the PDB ID: 1A7V\n",
      "QTDVIAQRKAILKQMGEATKPIAAMLKGEAKFDQAVVQKSLAAIADDSKKLPALFPADSKTGGDTAALPKIWEDKAKFDDLFAKLAAAATAAQGTIKDEASLKANIGGVLGNCKSCHDDFRAKKS\n"
     ]
    }
   ],
   "source": [
    "pdb=input(\"Enter the PDB ID: \")\n",
    "seq=str(fasta(pdb))\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the PDB ID: 1A7V\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['A104H',\n",
       " 'K97H',\n",
       " 'A91H',\n",
       " 'K84H',\n",
       " 'E73H',\n",
       " 'A66H',\n",
       " 'D58H',\n",
       " 'K49H',\n",
       " 'K39H',\n",
       " 'K31H',\n",
       " 'K20H',\n",
       " 'K13H',\n",
       " 'D3H']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdb=input(\"Enter the PDB ID: \")\n",
    "variations=mutation(pdb)\n",
    "var_list=variations.Result()\n",
    "var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHANGED PROTEIN REPRESENTATION: \n",
      "QT\u001b[1;32mH\u001b[0mVIAQRKAIL\u001b[1;32mH\u001b[0mQMGEAT\u001b[1;32mH\u001b[0mPIAAMLKGEA\u001b[1;32mH\u001b[0mFDQAVVQ\u001b[1;32mH\u001b[0mSLAAIADDS\u001b[1;32mH\u001b[0mKLPALFPA\u001b[1;32mH\u001b[0mSKTGGDT\u001b[1;32mH\u001b[0mALPKIW\u001b[1;32mH\u001b[0mDKAKFDDLFA\u001b[1;32mH\u001b[0mLAAAAT\u001b[1;32mH\u001b[0mAQGTI\u001b[1;32mH\u001b[0mDEASLK\u001b[1;32mH\u001b[0mNIGGVLGNCKSCHDDFRAKKS\n"
     ]
    }
   ],
   "source": [
    "res_num=[]\n",
    "for i in range(len(var_list)):\n",
    "    res_num.append(int(var_list[i][1:len(var_list[i])-1])-1)\n",
    "\n",
    "highlighted_sequence = list(seq)\n",
    "\n",
    "for i,ind in enumerate(res_num):\n",
    "    seq=seq[:ind] + var_list[i][len(var_list[i])-1] + seq[ind + 1:]\n",
    "for idx in res_num:\n",
    "    if idx < len(seq):\n",
    "        highlighted_sequence[idx] = '\\033[1;32m' + seq[idx] + '\\033[0m'  # Bold green color\n",
    "\n",
    "highlighted_sequence = ''.join(highlighted_sequence)\n",
    "print(\"CHANGED PROTEIN REPRESENTATION: \")\n",
    "print(highlighted_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_generate(pdb):\n",
    "    seq=str(fasta(pdb))\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cid_generate(pdb):\n",
    "    cid=str(drug_id(pdb))\n",
    "    return cid\n",
    "\n",
    "def smiles_generate(cid):\n",
    "    smile=str(drug_smiles(cid))\n",
    "    return smile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the path to the CSV file\n",
    "csv_file_path = \"protein_change_dataset.csv\"\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "s=df[\"PDB ID\"][0]\n",
    "for i in range(500,1000):\n",
    "    if(s!=(df[\"PDB ID\"][i])):\n",
    "        s=df[\"PDB ID\"][i]\n",
    "        df[\"SMILES\"][i]=smiles_generate(cid_generate(df[\"PDB ID\"][i]))\n",
    "        smile=df[\"SMILES\"][i]\n",
    "    else:\n",
    "        df[\"SMILES\"][i]=smile\n",
    "\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# print(sequence_generate(df[\"PDB ID\"][16]))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCCCCCCCOCCOCCOCCOCCO\n"
     ]
    }
   ],
   "source": [
    "# print(len(\"MEQRITLKDYAMRFGQTKTAKDLGVYQSAINKAIHAGRKIFLTINADGSVYAEEVKPFPSNKKTTA\"))\n",
    "print(smiles_generate(cid_generate(\"1BXW\")))\n",
    "# print((smiles_generate(\"TRS\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRUG Featurization - Molecular Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rdkit in c:\\users\\sasin\\anaconda3\\lib\\site-packages (2023.3.3)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy in c:\\users\\sasin\\anaconda3\\lib\\site-packages (from rdkit) (1.24.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\sasin\\anaconda3\\lib\\site-packages (from rdkit) (9.4.0)\n"
     ]
    }
   ],
   "source": [
    "pip install rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "\n",
    "# Define the SMILES representation\n",
    "smiles = \"Cc1c2n3c(c1CCC(=O)O)C=C4C(=C(C5=nn4[Fe]36[n]7=C(C=C8N6C(=C5)C(=C8C)C=C)C(=C(C7=C2)C)C=C)C)CCC(=O)O\"\n",
    "\n",
    "# Generate RDKit molecule object from SMILES\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "# Compute Morgan fingerprint for the molecule\n",
    "fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=1024)\n",
    "\n",
    "# Convert fingerprint to a list of integers\n",
    "embedding = list(fp.ToBitString())\n",
    "\n",
    "# Print the molecular embedding\n",
    "print(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting word2vec\n",
      "  Downloading word2vec-0.11.1.tar.gz (42 kB)\n",
      "     ---------------------------------------- 0.0/42.3 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/42.3 kB 320.0 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 41.0/42.3 kB 487.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 41.0/42.3 kB 487.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 41.0/42.3 kB 487.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.3/42.3 kB 170.6 kB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.9.2 in c:\\users\\sasin\\desktop\\fyp\\myenv\\lib\\site-packages (from word2vec) (1.25.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\sasin\\desktop\\fyp\\myenv\\lib\\site-packages (from word2vec) (1.3.2)\n",
      "Building wheels for collected packages: word2vec\n",
      "  Building wheel for word2vec (pyproject.toml): started\n",
      "  Building wheel for word2vec (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for word2vec: filename=word2vec-0.11.1-py2.py3-none-any.whl size=515232 sha256=4c12d290a02d6b350b68ea4b5723de15596d0c9e40ce6de1731b42eb86073965\n",
      "  Stored in directory: c:\\users\\sasin\\appdata\\local\\pip\\cache\\wheels\\53\\1f\\b2\\ff3d47b2a8bd249985b0c59210004a85d70ec90bbcff8aaa93\n",
      "Successfully built word2vec\n",
      "Installing collected packages: word2vec\n",
      "Successfully installed word2vec-0.11.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical vector representation of the protein sequence:\n",
      "[-2.8987736e-03  3.0627470e-03  2.2728157e-03  3.8841730e-03\n",
      "  4.2203072e-04 -3.8373983e-03  3.3998657e-03  7.0845508e-03\n",
      " -5.3717513e-03 -3.9739129e-03  2.3278310e-03 -3.8271488e-03\n",
      " -1.6229415e-03  1.8185355e-03  1.1509921e-03 -1.0562526e-03\n",
      "  3.7187706e-03  1.9568366e-03 -4.5918473e-03 -7.8693861e-03\n",
      "  1.8170821e-03  5.1551040e-05  6.7809084e-03 -2.5677844e-03\n",
      "  1.3584754e-03 -2.1501814e-04 -1.8393039e-03  4.2340402e-03\n",
      " -3.7932463e-03  9.2868222e-04  1.5200403e-03 -3.0595581e-03\n",
      "  2.0755895e-03 -4.2428384e-03 -1.0973689e-03  1.5817487e-03\n",
      "  3.9339522e-03  4.2890065e-04 -2.8366948e-04 -2.4935167e-04\n",
      "  2.4080713e-04 -8.1286352e-04 -5.2114618e-03  1.6297571e-03\n",
      "  1.5968863e-03  5.4882647e-04 -1.6813584e-03  1.5239865e-03\n",
      "  1.6982908e-03  3.0008524e-03 -8.4724263e-05 -1.5563399e-03\n",
      " -4.5481027e-04 -1.2043931e-03 -6.0078059e-04 -1.7196829e-03\n",
      "  2.1259147e-03 -1.8600508e-03 -6.1494525e-04  2.7567921e-03\n",
      " -1.4004121e-03 -8.4001798e-04  2.9679479e-03 -2.3645521e-03\n",
      " -2.1189409e-03  4.3046088e-03  2.0490815e-03  5.0162817e-03\n",
      " -3.2320220e-03  1.2863680e-03  1.3437150e-03  4.2269561e-03\n",
      "  2.6460469e-03  1.2991799e-03  1.5758589e-03  1.0957926e-03\n",
      "  2.3139974e-03  7.7759381e-04 -5.6384056e-04 -4.5792400e-03\n",
      " -4.0000430e-03  5.0832226e-05  1.8057382e-03  1.9105036e-03\n",
      " -1.4094072e-03 -2.4022812e-03  3.1831630e-03 -3.3891078e-03\n",
      "  1.3775007e-03  1.1459804e-03  1.2977809e-03  1.3695827e-03\n",
      "  2.4687103e-03 -1.6032826e-03  7.4740835e-03  2.5273864e-03\n",
      "  4.9812556e-04 -2.8783516e-03  1.3032324e-03  1.2915712e-03]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Example protein sequence\n",
    "protein_sequence = \"QTDVIAQRKAILKQMGEATKPIAAMLKGEAKFDQAVVQKSLAAIADDSKKLPALFPADSKTGGDTAALPKIWEDKAKFDDLFAKLAAAATAAQGTIKDEASLKANIGGVLGNCKSCHDDFRAKKS\"\n",
    "\n",
    "# Tokenize the protein sequence into individual amino acids\n",
    "amino_acids = [aa for aa in protein_sequence]\n",
    "\n",
    "# Train a Word2Vec model on a corpus of protein sequences\n",
    "# For demonstration purposes, we'll use a small corpus consisting of the input sequence itself\n",
    "corpus = [amino_acids]\n",
    "word2vec_model = Word2Vec(sentences=corpus, vector_size=100, window=5, min_count=1, sg=1)\n",
    "\n",
    "# Convert each amino acid into its corresponding Word2Vec embedding vector\n",
    "embedding_size = word2vec_model.vector_size\n",
    "sequence_vectors = [word2vec_model.wv[aa] for aa in amino_acids]\n",
    "\n",
    "# Aggregate the embedding vectors to obtain a single numerical vector representation for the protein sequence\n",
    "protein_vector = np.mean(sequence_vectors, axis=0)\n",
    "\n",
    "# Print the numerical vector representation\n",
    "print(\"Numerical vector representation of the protein sequence:\")\n",
    "print(protein_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdkit.Chem as Chem\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import networkx as nx\n",
    "import torch_geometric as pyg\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "nx_graph=[]\n",
    "length=[]\n",
    "# Convert the SMILES string to an RDKit molecule object\n",
    "for x in range(0,1):\n",
    "    mol = Chem.MolFromSmiles(\"C1=CC=C(C=C1)C2=CC(=O)C3=C(C(=C(C=C3O2)O[C@H]4[C@@H]([C@H]([C@@H]([C@H](O4)C(=O)O)O)O)O)O)O\")\n",
    "#     print(mol)\n",
    "    # Create an empty NetworkX graph\n",
    "    nx_graph.append(nx.Graph())\n",
    "    l=0\n",
    "    # Add nodes  to the graph\n",
    "    for atom in mol.GetAtoms():\n",
    "    #     print(atom.GetSymbol())\n",
    "        l=l+1\n",
    "        atom_idx = atom.GetIdx()\n",
    "        atom_symbol = atom.GetSymbol()\n",
    "        nx_graph[x].add_node(atom_idx, atom_symbol=atom_symbol)\n",
    "    length.append(l)\n",
    "    # print(length)\n",
    "    label_list=[]\n",
    "    for i in range(l):\n",
    "        label_list.append('C')\n",
    "    # Add edges  to the graph\n",
    "    for bond in mol.GetBonds():\n",
    "        start_atom_idx = bond.GetBeginAtom().GetIdx()\n",
    "        s_atom=bond.GetBeginAtom().GetSymbol()\n",
    "    #     s_atom_idx= s_atom\n",
    "        end_atom_idx = bond.GetEndAtom().GetIdx()\n",
    "        e_atom=bond.GetEndAtom().GetSymbol()\n",
    "        bond_type = bond.GetBondTypeAsDouble()\n",
    "        nx_graph[x].add_edge(start_atom_idx, end_atom_idx, bond_type=bond_type)\n",
    "        label_list[start_atom_idx]=s_atom\n",
    "        label_list[end_atom_idx]=e_atom\n",
    "#         print(\"(\",s_atom,\"[\",start_atom_idx,\"]\",e_atom,\"[\",end_atom_idx,\"]) ->\",nx_graph[start_atom_idx][end_atom_idx]['bond_type'])\n",
    "\n",
    "\n",
    "    # print(nx_graph.edges)\n",
    "    # Visualization\n",
    "    pos = nx.spring_layout(nx_graph[x])\n",
    "      #nx.draw(nx_graph, pos, with_labels=True,labels=dict(enumerate(label_list)),node_size=500, node_color=\"lightblue\")\n",
    "    nx.draw(nx_graph[x], pos, with_labels=True,node_size=500, node_color=\"lightblue\")\n",
    "#     plt.show()\n",
    "print(length)\n",
    "\n",
    "\n",
    "# print(bond_types)\n",
    "# Convert the NetworkX graph to a PyTorch Geometric Data object\n",
    "gnn_arr_drug=[]\n",
    "# print(len(data))\n",
    "for x in range(0,1):\n",
    "    data1 = pyg.utils.from_networkx(nx_graph[x])\n",
    "    seed = 40\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "    # Create one-hot encoding for 'atom_symbol'\n",
    "    atom_symbols = [nx_graph[x].nodes[node]['atom_symbol'] for node in nx_graph[x].nodes()]\n",
    "    unique_symbols = list(set(atom_symbols))\n",
    "    symbol_to_index = {symbol: i for i, symbol in enumerate(unique_symbols)}\n",
    "    one_hot_encoded_symbols = torch.eye(len(unique_symbols))[torch.tensor([symbol_to_index[symbol] for symbol in atom_symbols])]\n",
    "    # print(one_hot_encoded_symbols)\n",
    "    # Set 'x' in the data object as one-hot encoded symbols\n",
    "    data1.x = one_hot_encoded_symbols\n",
    "\n",
    "    # print(data.x)\n",
    "    # Set 'edge_attr' in the data object as bond types\n",
    "\n",
    "\n",
    "    class GNNModel(nn.Module):\n",
    "        def __init__(self, node_input_dim, hidden_dim):\n",
    "            super(GNNModel, self).__init__()\n",
    "            self.conv1 = pyg.nn.GCNConv(node_input_dim, hidden_dim)\n",
    "            self.conv2 = pyg.nn.GCNConv(hidden_dim, hidden_dim)\n",
    "\n",
    "        def forward(self, data1):\n",
    "            x, edge_index = data1.x, data1.edge_index\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = self.conv2(x, edge_index)\n",
    "            return x\n",
    "\n",
    "    # Create an instance of your GNN model\n",
    "    node_input_dim = one_hot_encoded_symbols.size(1)  # Input dimension is the number of one-hot encoded symbols\n",
    "#     print(node_input_dim)\n",
    "    hidden_dim = 167\n",
    "\n",
    "    gnn_model = GNNModel(node_input_dim, hidden_dim)\n",
    "\n",
    "    # Pass the data through your GNN model to extract node features\n",
    "    # print(data)\n",
    "    gnn_model.eval()\n",
    "    node_features = gnn_model(data1)\n",
    "    # print(node_features)\n",
    "    # Convert the node features to a consistent list\n",
    "    node_features_list = node_features.tolist()\n",
    "#     print(node_features.shape)\n",
    "    # print(node_features)\n",
    "\n",
    "\n",
    "    # Calculate the sum of all the features to check consistency\n",
    "    # sum_of_features = sum([sum(features) for features in node_features_list])\n",
    "    # print(sum_of_features)\n",
    "\n",
    "    gnn_feature_values=[]\n",
    "    for i in range(0,hidden_dim):\n",
    "        sum1=0.0\n",
    "        for j in range(0,length[x]):\n",
    "            sum1+=node_features[j][i]\n",
    "        gnn_feature_values.append(sum1.item())\n",
    "\n",
    "#     print(gnn_feature_values)\n",
    "    gnn_arr_drug.append(gnn_feature_values)\n",
    "\n",
    "    # lt=[]\n",
    "    # for i in node_features:\n",
    "    #     lt1=[]\n",
    "    #     for j in i:\n",
    "    #         val=(float)(j.detach().numpy())\n",
    "    #         lt1.append(val)\n",
    "    #     lt.append(lt1)\n",
    "    # node_features1 = lt   commented for changed values in flattened list\n",
    "    # print(node_features1)\n",
    "\n",
    "    flattened_list = [item for sublist in node_features_list for item in sublist]\n",
    "    # print(flattened_list)\n",
    "    # g=torch.mean(flattened_list,dim=0)\n",
    "    # g_list=g.tolist()\n",
    "    # print(g_list)\n",
    "    # col=len(flattened_list[0])\n",
    "    # print(row,col)\n",
    "    # node_features now contains the extracted features for each node in your graph\n",
    "\n",
    "print(len(gnn_arr_drug[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
